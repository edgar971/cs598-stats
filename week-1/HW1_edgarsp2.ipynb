{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 542 / CS 598: Example Homework\n",
    "\n",
    "Spring 2019, by Edgar Pino (edgarsp2)\n",
    "\n",
    "Due: Monday, Sep 9 by 11:59 PM Pacific Time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 [50 Points] KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1A. [15 Points] Write a function myknn(xtest, xtrain, ytrain, k) that fits a KNN model that predict a target point or multiple target points xtest. Here xtrain is the training dataset covariate value, ytrain is the training data outcome, and k is the number of nearest neighbors. Use the ℓ2 norm to evaluate the distance between two points. Please note that you cannot use any additional R package within this function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(a, b):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.sqrt(np.sum(np.square(a - b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_average(neighbors):\n",
    "    return np.average(neighbors[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(trainingSet, instance, k):\n",
    "    distances = []\n",
    "\n",
    "    for x in range(len(trainingSet)):\n",
    "        distance = get_distance(instance, trainingSet[x][:-1])\n",
    "        distances.append((trainingSet[x], distance))\n",
    "\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    \n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0]) \n",
    "    return np.array(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myknn(xtest, xtrain, ytrain, k):\n",
    "    nn = []\n",
    "    training_data_xy = []\n",
    "    \n",
    "    for i in range(len(xtrain)):\n",
    "        training_data_xy.append(np.append(xtrain[i],[ytrain[i]]))\n",
    "        \n",
    "    for i in range(len(xtest)):\n",
    "        neighbors = get_neighbors(training_data_xy, xtest[i], k)\n",
    "        predicted_label = get_label_average(neighbors)\n",
    "        nn.append(predicted_label)\n",
    "        \n",
    "    return np.array(nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B. [10 Points] Generate 1000 observations from a five-dimensional normally distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cov(): \n",
    "    cov = np.zeros((5,5))\n",
    "    for i in range(1,6):\n",
    "        for j in range(1,6):\n",
    "            cov[i-1][j-1] = pow(.5,(abs(i-j)))\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [1,2,3,4,5]\n",
    "cov = get_cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.multivariate_normal(mean, cov, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_epsilon = np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x[:,0] + x[:,1] + np.square((x[:,2] - 2.5)) + y_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 values of X: [[-0.20645625  0.62507688  1.7750502   2.40691521  5.18134863]\n",
      " [ 3.7402364   4.40503372  4.35016723  4.96114578  5.39520319]\n",
      " [-0.86926549 -0.28132208  2.10283711  3.41796534  5.90390064]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"First 3 values of X: {x[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 values of Y: [ 0.01941756 12.6972788  -2.12164048]\n"
     ]
    }
   ],
   "source": [
    "print(f\"First 3 values of Y: {y[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1C. [10 Points] Use the first 400 observations of your data as the training data and the rest as testing data. Predict the Y values using your KNN function with k = 5. Evaluate the prediction accuracy using mean squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(y_true, y_pred):\n",
    "    return np.square(np.subtract(y_true,y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = x[:400], x[400:], y[:400], y[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = myknn(X_test, X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_knn_c_mse = mean_square_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.5558223877014192\n"
     ]
    }
   ],
   "source": [
    "print(f\"MSE: {my_knn_c_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D. [15 Points] Compare the prediction error of a linear model with your KNN model. Consider k being 1, 2, 3, …, 9, 10, 15, 20, …, 95, 100. Demonstrate all results in a single, easily interpretable figure with proper legends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(['ggplot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_y_pred_d = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_mse_d = mean_square_error(y_test, lm_y_pred_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = np.arange(1,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mses = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(k_vals)):\n",
    "    y_pred = myknn(X_test, X_train, y_train, k_vals[i])\n",
    "    knn_mses[i] = mean_square_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(knn_mses,'-o', color='blue')\n",
    "plt.axhline(y=lm_mse_d, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 [50 Points] Linear Regression through Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A. [35 Points] Based on this description, write your own R function mylm_g(x, y, delta, epsilon, maxitr) to implement this optimization version of linear regression. The output of this function should be a vector of the estimated beta value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, b, delta, epsilon, maxitr):\n",
    "    iterations = 1\n",
    "    cost_history = []\n",
    "    m = len(y)\n",
    "\n",
    "    while True:\n",
    "        h = x.dot(b)\n",
    "        loss = h - y\n",
    "\n",
    "        gradient = x.T.dot(loss) / m\n",
    "\n",
    "        b_new = b - delta * gradient\n",
    "\n",
    "        cost = np.sum(abs(b_new - b))\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        b = b_new\n",
    "        \n",
    "        if cost < epsilon:\n",
    "            break\n",
    "            \n",
    "        if iterations == maxitr:\n",
    "            break\n",
    "        \n",
    "        iterations +=1\n",
    "\n",
    "    return b, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mylm_g(x, y, delta, epsilon, maxitr):\n",
    "    beta = np.zeros(x.shape[1])\n",
    "    newB, _ = gradient_descent(x, y, beta, delta, epsilon, maxitr)\n",
    "    return newB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B. [15 Points] Test this function on the Boston Housing data from the mlbench package. Documentation is provided here if you need a description of the data. We will remove medv, town and tract from the data and use cmedv as the outcome. We will use a scaled and centered version of the data for estimation. Please also note that in this case, you do not need the intercept term. And you should compare your result to the lm() function on the same data. Experiment on different maxitr values to obtain a good solution. However your function should not run more than a few seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('./boston-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop([x.columns[0],'medv', 'town', 'tract'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(scale(x), index=x.index, columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.cmedv.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop(['cmedv'],axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train params\n",
    "delta = 0.1\n",
    "epsilon = 1e-7\n",
    "max_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_beta_2b = mylm_g(x,y, delta, epsilon, max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_beta_2b = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df = pd.DataFrame({'LinearRegression': lm_beta_2b, 'mylm_g': my_beta_2b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearRegression</th>\n",
       "      <th>mylm_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.032316</td>\n",
       "      <td>-0.032317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030245</td>\n",
       "      <td>0.030245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097936</td>\n",
       "      <td>-0.097936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118273</td>\n",
       "      <td>0.118272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011390</td>\n",
       "      <td>0.011388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.071312</td>\n",
       "      <td>0.071313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.199704</td>\n",
       "      <td>-0.199703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.287233</td>\n",
       "      <td>0.287233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007565</td>\n",
       "      <td>0.007565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.321039</td>\n",
       "      <td>-0.321039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.290851</td>\n",
       "      <td>0.290846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.236526</td>\n",
       "      <td>-0.236521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.206805</td>\n",
       "      <td>-0.206805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.091235</td>\n",
       "      <td>0.091235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.417973</td>\n",
       "      <td>-0.417973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LinearRegression    mylm_g\n",
       "0          -0.032316 -0.032317\n",
       "1           0.030245  0.030245\n",
       "2          -0.097936 -0.097936\n",
       "3           0.118273  0.118272\n",
       "4           0.011390  0.011388\n",
       "5           0.071312  0.071313\n",
       "6          -0.199704 -0.199703\n",
       "7           0.287233  0.287233\n",
       "8           0.007565  0.007565\n",
       "9          -0.321039 -0.321039\n",
       "10          0.290851  0.290846\n",
       "11         -0.236526 -0.236521\n",
       "12         -0.206805 -0.206805\n",
       "13          0.091235  0.091235\n",
       "14         -0.417973 -0.417973"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "title": ""
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
