plot(cars)
health_data= read.csv("mydata.csv")
health_data= read.csv("data/sepsis.csv")
### Randomly split the data into 75% for training and 25% for testing.
### Answer:
```{r}
health_data= read.csv("data/sepsis.csv")
library(MASS)
attach(Boston)
Boston
show(Boston)
poly()
x = Boston.dis
Boston['dis']
x = Boston['dis']
View(x)
y = Boston['knox']
y = Boston['nox']
poly(x)
poly(x, 1)
poly(x = x, 1)
model <- lm(y ~ poly(x,3))
model <- lm(y ~ poly(x,3, raw = TRUE))
View(x)
View(y)
View(x)
View(y)
model <- lm(x ~ poly(y,3, raw = TRUE))
poly(x = x, 1, raw =  True)
poly(x = x, 1, raw = True)
poly(x = x, 1, raw = raw=TRUE)
poly(x = x, 1, raw=TRUE)
fit<-lm(wage ~ bs(age,knots = c(25,40,60)),data = Wage )
fit<-lm(y ~ poly(x))
fit7=lm(medv~poly(lstat,4))
fit7=lm(medv~poly(lstat,4))
library(MASS)
attach(Boston)
fit7=lm(medv~poly(lstat,4))
plot(medv~lstat,Boston)
dis
plot(dis~nox,Boston)
fit7=lm(dis~poly(nox,4))
View(fit7)
fit7=lm(nox~poly(dis,4))
View(fit7)
fit7=lm(dis~poly(nox,4))
fit7=lm(nox~poly(dis,4))
model=lm(nox~poly(dis,4))
View(model)
summary(model)
deviance(model)
predict(model)
predict(model, 6)
c(6)
new_x c(6)
new_x  = c(6)
predict(model, new_x)
)newdata = data.frame(waiting=80)
newdata = data.frame(6)
View(newdata)
predict(model, newdata)
predict(model, newdata, interval="predict")
new <- data.frame(x = seq(6))
predict(model, new, interval="predict")
predict(model, newdata = new)
i = data.frame(6)
View(i)
predict(model, newdata = i)
predict(model, data.frame(nox=c(5,10,15)),interval="confidence"))
predict(model, data.frame(nox=c(5,10,15)),interval="confidence")
predict(model, data.frame(nox=c(6)),interval="confidence")
model=lm(nox~poly(dis,4), data = Boston)
model
deviance(model)
predict(model, data.frame(nox=c(5,10,15)),interval="confidence")
confint(model)
predict(model, data.frame(lstat=c(5, 10, 15)), interval="confidence")
predict(model, data.frame(nox=c(6)), interval="confidence")
predict(model, data.frame(dis=c(6)), interval="confidence")
predict(model, data.frame(dis=c(6)), interval="confidence")
summary(model)
model=lm(nox~poly(dis,3), data = Boston)
predict(model, data.frame(dis=c(6)), interval="confidence")
confint(model)
deviance(model)
predict(model, data.frame(dis=c(6)), interval="confidence")
summary(model)
model=lm(nox~poly(dis,4), data = Boston)
deviance(model)
predict(model, data.frame(dis=c(6)), interval="confidence")
model=lm(nox~poly(dis,4))
model2=lm(nox~poly(dis,4))
summary(model2)
predict(model, data.frame(dis=c(6)))
predict(model2, data.frame(dis=c(6)))
myfit1 = lm(nox ~ bs(dis, df=3), data=Boston)
library(MASS)
myfit1 = lm(nox ~ bs(dis, df=3), data=Boston)
library(MASS)
load(ElemStatLearn)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
zip.train
show(zip.train)
images = zip.train
View(images)
View(images)
write.csv(zip.train, 'zip.train.csv')
Sigma2 = matrix(c(0.1, 0, 0, 50), 2, 2)
View(Sigma2)
mu1 = c(3, 80)
View(mu1)
View(Sigma2)
Sigma1 = matrix(c(0.1, 0, 0, 10), 2, 2)
Sigma2 = matrix(c(0.1, 0, 0, 50), 2, 2)
View(Sigma1)
View(Sigma2)
rep(1, n
)
rep(1, n)
rep(1, 40)
c(rep(1, n)
)
c(rep(1, n))
c(rep(1, 40))
x <- c(rep(1, 40))
x - c(rep(1, 40))
x = c(rep(1, 40))
show(x)
View(x)
x = 40
matrix(c(rep(1, n), rep(-1, n)))
n <- 40
matrix(c(rep(1, n), rep(-1, n)))
y <- matrix(c(rep(1, n), rep(-1, n)))
View(y)
View(y)
nrow(y)
ncol(y)
dim
dim(y)
matrix(0,3,3)
Dmat       <- matrix(0,3,3)
diag(Dmat) <- 1
View(Dmat)
c(0,5,0)
dvec       <- c(0,5,0)
View(dvec)
data(spam)
library(ElemStatLearn)
data(spam)
force(spam)
View(spam)
View(spam)
View(spam)
library(e1071)
install.packages("e1071")
library(e1071)
library(ElemStatLearn)
data[,ncol(data)]
data[,ncol(spam)]
spam[, -1]
spam[, ncol(spam)]
y = spam[, ncol(spam)]
x = spam[, 1:4]
View(x)
x = spam[, :57]
x = spam[, 0:57]
View(x)
x = spam[, 0:59]
x = spam[, 0:58]
x = spam[, 0:57]
x = spam[, 0:58]
View(x)
x = spam[, 0:57]
x = spam[, 1:57]
View(x)
y = spam[, ncol(spam)]
View(y)
svm(x, y, kernel = "linear", cost = 10, scale = FALSE)
svm(x, y, kernel = "linear", cost = 1)
model = svm(x, y, kernel = "linear", cost = 1)
print(model)
pred <- predict(model, x)
prex
pred
table(pred, y)
xtab = table(pred, y)
library(caret)
confusionMatrix(xtab)
install.packages("caret")
library(caret)
confusionMatrix(xtab)
b=(1,1,1)
b->(1,1,1)
b->(1,1,1)
c(1,1,1)
a->c(1,1,1)
a<-c(1,1,1)
a[0]
a[1]
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
PL <- function(b) {
sum(r
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
r^2
2^
2^2
b<-c(1,1,1)
b
+0.5*(b[0]^2+b[1]^2+b[2]^2)
result<-0.5*(b[0]^2+b[1]^2+b[2]^2)
0.5*(b[0]^2+b[1]^2+b[2]^2)
5^5
5^2
0.5*(b[0]^2+b[1]^2+b[2]^2)
0.5*(b[0]^2+b[1]^2+b[2]^2)
b[0]^2
b[0]^2
b[0]
b[1]
+0.5*(b[1]^2+b[2]^2+b[3]^2)
+0.5*(b[1]^2+b[2]^2+b[3]^2)
0.5*(b[1]^2+b[2]^2+b[3]^2)
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
res <- optim(c(1,1,1), PL, method = "BFGS")
intercept_decision = -res$par[1]/res$par[3]
slope = -res$par[2]/res$par[3]
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
res <- optim(c(1,1,1), PL, method = "BFGS")
intercept_decision = -res$par[1]/res$par[3]
slope = -res$par[2]/res$par[3]
set.seed(1)
n = 100 # number of data points for each class
p = 2 # dimension
xpos <- matrix(rnorm(n*p,mean=0,sd=1),n,p)
xneg <- matrix(rnorm(n*p,mean=1.5,sd=1),n,p)
x <- rbind(xpos,xneg)
y <- c(rep(-1, n), rep(1, n))
plot(x,col=ifelse(y>0,"darkorange", "deepskyblue"), pch = 19, xlab = "x1", ylab = "x2")
legend("topleft", c("Positive","Negative"), col=c("darkorange", "deepskyblue"),
pch=c(19, 19), text.col=c("darkorange", "deepskyblue"))
+0.5*(b[1]^2+b[2]^2+b[3]^2)
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
res <- optim(c(1,1,1), PL, method = "BFGS")
View(res)
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
res <- optim(c(1,1,1), PL, method = "BFGS")
exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
)
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
res <- optim(c(1,1,1), PL, method = "BFGS")
(b[1]+x%*%c(b[2],b[3]))
(b[1]+x%*%c(b[2],b[3]))
slope = -res$par[2]/res$par[3]
intercept_decision = -res$par[1]/res$par[3]
slope = -res$par[2]/res$par[3]
abline(a=intercept_decision, b=slope)
View(x)
write.csv(x, 'xr.csv')
write.csvyx, 'yr.csv')
write.csv(y, 'yr.csv')
View(res)
PL <- function(b) {
sum(
log(1+exp(
-y*
(b[1]+x%*%c(b[2],b[3]))
))
)+0.5*(b[1]^2+b[2]^2+b[3]^2)
}
res <- optim(c(1,1,1), PL, method = "BFGS")
View(res)
abline(a=-1.3611, b=0.812670)
set.seed(1)
n = 400
p = 2 # dimension
View(x)
x <- matrix(runif(n*p), n, p)
View(x)
plot(x[1], x[2])
plot(x)
side <- (x[, 2] > 0.5 + 0.3*sin(3*pi*x[, 1]))
View(side)
sample(c(1, -1), n, TRUE, c(0.9, 0.1))*(side == 1)
dist
help("dist")
set.seed(1)
n = 400
p = 2 # dimension
# Generate the positive and negative examples
x <- matrix(runif(n*p), n, p)
side <- (x[, 2] > 0.5 + 0.3*sin(3*pi*x[, 1]))
y <- sample(c(1, -1), n, TRUE, c(0.9, 0.1))*(side == 1) + sample(c(1, -1), n, TRUE, c(0.1, 0.9))*(side == 0)
K =exp(-1 * as.matrix(dist(x)^2)/0.25)
View(K)
K =exp(-1 * as.matrix(dist(x)^2)/0.25)
dist(x)
edgar=dist(x)
dist(x)^2
i=dist(x)^2
K =exp(-1 * as.matrix(dist(x)^2)/0.25)
as.matrix(dist(x)^2)
test=as.matrix(dist(x)^2)
adist(x)^2
a=dist(x)^2
test=as.matrix
as.matrix(1)
as.matrix([1,2])
as.matrix((4,5,))
as.matrix((4,5,4))
